2021/02/16

Here's the remaining work:

1. Split "Method" into "Pilot" and "Method"
	A. Ch 3: "Pilot": 2/16: COMPLETE
	B. Ch 6: "Method": 2/17
	C. Revise "Data", "Annotation" accordingly: 2/18
2. Write "Optimization"
	A. Transitivity: 2/22
	B. Targeting: 2/23
	C. Familiarity: 2/24
	D. Primacy: 2/25
	E. Term Norm: COMPLETE
	F. Term representation: 2/19
	G. Combinations and trends: 3/2
	H. Bert vs Me: 3/4
3. Write Lit Review: 3/12
4. Write Intro: 3/22
5. Write Conclusion: 3/31


2021/02/24:
Today I want to grind out all the stats results I need from that csv of 360 spearman scores.



2021/02/26, Friday.
Meeting with Markus in 10 minutes.
TODO:
Fix term norm results table (make parallel to others)
Add BERT (baseline) scores throughout
Add discussion to results
	dig into what the scores represent, guided by stats, deviations from BERT
	Example:
		Term Representation:
			ldh has highest mean, but xdx has highest max (and highest min)
			xdh has highest median
			What's the story here?
			
From meeting:
Investigate p values for mins and maxs and go from there
Investigate Table 6.6--these probably shouldn't be negatives!

Check in in a week with email updates;
Meet on 3/12 at 1:30pm.
################################################################################


2021/02/28, Sunday. BERT.
################################################################################

2021/03/01. Monday. BERT.
Today:
Complete BERT script;
Run BERT on my data;
Generate Spearman scores (BERT vs Weighted Annotation);
DONE;
Tomorrow: modify and rerun thesis_spearman_stats.py to include BERT scores
################################################################################

2021/03/09. Tuesday.
When BERT is finished running on all N14 samples, run get_bert_spearman_correlations.py.
update thesis_bert_spearman_stats.py (cf thesis_spearman_stats.py); run it.
DONE

##
ARGH! I've been using BERT in training mode (default?); this results in non-deterministic scores.
I'm going to run it again in "eval" mode.:
#
Run BERT N14 vs N70:
change bert_vs_sails.py: train_sample = 'N14'
change get_bert_spearman_correlations.py: train_sample = 'N14'
change thesis_bert_spearman_stats.py: train_sample = 'N14'
python bert_vs_sails.py
python get_bert_spearman_correlations.py
python thesis_bert_spearman_stats.py
DONE ALL
#
Run BERT N50 vs N70:
change bert_vs_sails.py: train_sample = 'N50'
change get_bert_spearman_correlations.py: train_sample = 'N50'
change thesis_bert_spearman_stats.py: train_sample = 'N50'
python bert_vs_sails.py
DONE
python get_bert_spearman_correlations.py
DONE
python thesis_bert_spearman_stats.py
DONE
#
###
TODO:
UPDATE ALL CHAPTER 6 TABLES WRT BERT SCORES!
###


################################################################################
2021-03-12.
Updating Chapter 6 now.
TODO:
Regenerate / check numbers for term norm table (currently 6.6); reconcile this table format with others throughout chapter 6.
Write discussion of Spearman correlation; why use Spearman (vs Pearson, etc)? What is the range of Spearman scores and what do they mean? (1.0, 0, -0.5, -1.0)
Write discussion of BERT; what it is/does, how it works; training data; model and implementation used;


Questions for Markus:
How to best highlight information in the Tables?
Does it make sense to highlight the highest (or lowest) standard deviation?

################################################################################
2021-03-26.
TODO:
Complete Familiarity experiments and tables;
################################################################################
Discussion of BERT / SBERT;
inputs, outputs;
mention and cite architecture, but not in detail;
what do we learn from using BERT w.r.t. my system? BERT wins, so we should abandon my system? (NO, but elaborate)
################################################################################
Email Markus on 4/2;
meet again on 4/9;

################################################################################
################################################################################
TODO:
###
CHANGE TO N14 and run:
python get_all_tfidf_cosines-weighted_deps.py DONE

CHANGE TO N14 and run:
python get_all_spearman_correlations.py DONE

CHANGE TO N14 and run:
python thesis_spearman_stats.py DONE

###
CHANGE TO F14 and run:
python get_all_tfidf_cosines-weighted_deps.py DONE

CHANGE TO F14 and run:
python get_all_spearman_correlations.py DONE

CHANGE TO F14 and run:
python thesis_spearman_stats.py DONE

###
CHANGE TO N50 and run:
python get_all_tfidf_cosines-weighted_deps.py DONE

CHANGE TO N50 and run:
python get_all_spearman_correlations.py DONE

CHANGE TO N50 and run:
python thesis_spearman_stats.py DONE

## For UNWEIGHTED F14 and N14 "term_vectors" folders -- restore these from Github DONE
################################################################################

2021-04-01. Thursday.
Today:
Grind out the last of the table work in Ch. 6:
	Confirm which configurations should be covered by each;
		Confirm that the correct file (exists and) is used;
		Confirm that the numbers in the tables are correct;
Dig into the table and trends for Transitivity (currently Table 6.2);
	"Observe and report" -- any explanations for trends?
Same for remaining parameter stats tables in Ch. 6....


Starting from term-norm table because that might involve some more coding to get the numbers...
Yep. Adapting get_bert_spearman_correlations.py to get_bert_spearman_correlations-weighted_deps.py.
Run this for F14-W, N14-W, N50-W. DONE
Then...
Adapting thesis_spearman_stats.py to combined_thesis_spearman_stats.py to operate on the combined_spearman_Nxx-VS-N70.csv... DONE
it generates the appropriate spearman_stats csvs in the stats/* folders.
Run this for Nxx =
weighted N14, N50, F14 DONE
unweighted N14, N50, F14 DONE
I have confirmed that the descriptive stats produced are correct -- I verified it with formulas in the spearman csvs the descriptive stats are based on.

I can now complete the term-norm table. DONE
Double-check these tables:
term-rep:
familiarity:
primacy:
targeting:
transitivity:
ALL DONE

################################################################################

2021-04-02. Friday.
Still working on the list from yesterday.
Why do some rankings have such high p-values?
What is going on with the negative Spearman correlations?

Observations:

I've gone over all the tables, noted some observations and now I'm going from there. The good news is that I'm fairly confident there are some trends I can latch on to. The most salient to me has been the effect of the size of the NS models. Throughout I compare "N14" models (14 NS responses) and N50 models; the N14 models typically outperform the N50 models when the conditions are relatively constrained: Targeted vs Untargeted, Primary vs Mixed (first responses vs first + second responses), and Intransitives vs Transitives/Ditransitives. "Constrained" might not be the right word, but these conditions tend to produce lower type-to-token ratios, which I'm also working to incorporate into the discussion.

Right now I'm focusing on the discussion of transitivity and the related Spearman stats. I'm aiming to finish that section over the weekend, because I think whenever you next get a chance to provide some feedback, it would be helpful to know if I'm on the right track with the similar sections.


Table 6.2 Transitivity:
	For both samples (N14 and N50):
		System scores: intrans > trans > ditrans
		BERT scores: trans > intrans > ditrans
	System rarely beats BERT: Intransitive max (N14, N50); Transitive min (N14);
	For System mean and median, N50 beats N14 for trans and ditrans, but is worse for intrans;
	For BERT mean and median, N50 beats N14 for intrans and ditrans, but is worse for trans;
	Suggests that choices relating to sample size and the use of BERT vs system could be optimized for items according to transitivity.

Table 6.3 Targeting:
	Targ > Untarg (always--system & BERT, both sample sizes)
	For System mean and median: N14 narrowly beats N50 for Targeted; N14 narrowly loses to N50 for Untargeted;
		Suggests that smaller samples work better than larger samples under more constrained conditions (i.e., likely higher type-to-token ratio? cf Transitivity Table 6.2 and similar pattern for intransitives)
	For BERT mean and median: N50 is always better than N14 (Targ and Untarg)
	For Untargeted, System achieves a higher max than BERT (N14 and N50)

Table 6.4 Primacy:
	System mean and median: For Primary, N14 > N50; for Mixed, N14 < N50;
	BERT mean and median: For Primary, N14 < N50;
		Mixed mean: N14 < N50; Mixed median: N14 > N50;
	System: For N14, Primary > Mixed; For N50, Primary < Mixed;
	BERT: For N14, there is very little difference between Primary and Mixed; Primary has slightly lower mean but slightly higher median than Mixed. But for N50, Primary mean and median are both slightly higher than Mixed.
		This suggests something about BERT's ability to zero in on the meaning common to all responses as it obvserves more examples. For System, the pattern is kind of intuitive--if you have a small model, you want those responses to be as on-target as possible, which happens with Primary responses; when you ask for second responses, you expand coverage but also get some lower-quality responses. Relatedly, if you do use second responses, it's probably best to do so in models that are large enough that a small number of bad responses cannot ruin the performance overall.
		Cf. Transitivity and Targeting tables; For more constrained contexts like intrans, targeted, or primary response models only, we see that System performs best with the N14 model (vs N50); this likely correlates with type-to-token ratios;

Table 6.5 Familiarity:
	System and BERT show slightly better performance for Familiar > Crowd. This is expected, but there's only N14 and not a lot to go on here.
	
Table 6.7 Term normalization:
	System: very little difference between Normalized and Non-Normalized models; slightly better performance from Non-normalized, more noticeable for N14 than N50.
	Term-normalization isn't worth doing.

Table 6.8 Term Representation:
	For System mean & median: ldh clearly benefits from more training data (N14 < N50); xdx clearly suffers from more training data (N14 > N50); xdh is roughly unchanged (i.e., it's between ldh and xdx in terms of this effect, as we'd expect).
	For N14, xdh is clearly best; xdh > ldh > xdx;
	For N50, ldh has the highest mean, but xdh has the highest median;
	xdx always has the highest minimum (including BERT);
	xdx seems best at these sample sizes; ldh is much more competetive at N50, so maybe there's a sample size where ldh > xdh. With larger datasets, I suspect the labels would become more meaningful, but it's possible that they introduce a bit of noise at these sample sizes.
	
################################################################################
################################################################################
4/9/2021
Still need:
Why do some rankings have such high p-values?
What is going on with the negative Spearman correlations?

Working on Transitivity section.
Question: Why does SBERT perform best on transitives?

"we use the dependency parse information to determine whether each noun is an A or an O, and if it is either we pass the whole sentence through mBERT and take the contextual embedding corresponding to the noun." --papadimitriou2021multilingual
How does this work? how do you get the embedding corresponding to the noun from the sentence embedding?

#########################
Re: Sturgill Simpson:
High top mountain album first, then meta modern sounds, and sailors guide to galaxy.

################################################################################
################################################################################
Citations, Lit Review, etc.
#####

@article{papadimitriou2021multilingual,
  title={Multilingual BERT, Ergativity, and Grammatical Subjecthood},
  author={Papadimitriou, Isabel and Chi, Ethan A and Futrell, Richard and Mahowald, Kyle},
  journal={Proceedings of the Society for Computation in Linguistics},
  volume={4},
  number={1},
  pages={425--426},
  year={2021}
}
###

@article{yamazaki2014,
  title={Toward integrative CALL: A progressive outlook on the history, trends, and issues of CALL},
  author={Yamazaki, Kasumi},
  journal={TAPESTRY},
  volume={6},
  number={1},
  pages={6},
  year={2014}
}
"...sociocultural theories of learning, mainly named as Kolb’s (1984) experiential learning and Lave and Wenger’s (1991) situated learning, which emphasize that learning occurs in a communicative context through concrete and direct experiences. Learning in this approach is generally exploratory, thus learners’ autonomy, engagement, and, most importantly, motivation are often found to be the most critical elements of contemporary CALL research (cf. Rahimi & Yodollahi, 2011; Ushioda, 2000; Schwienhorst, 2002; Mohammadi, Ghorbani, & Hamidi, 2011; AbuSeileek, 2012)."
#####
#####
@article{collentine2011,
  title={Learner autonomy in a task-based 3D world and production},
  author={Collentine, Karina},
  journal={Language Learning \& Technology},
  volume={15},
  number={3},
  pages={50--67},
  year={2011},
  publisher={University of Hawaii National Foreign Language Resource Center}
}
With widespread access to technology, learners are increasingly using CALL materials in a learner- centered approach where they take control of their own learning, on their own time, and for their own purposes. These materials include virtual and 3D environments with gaming-like experiences (Darasawang & Reinders, 2010; Sykes, 2009). Highly interactive, multi-sensory environments provide access to real world simulations (Pantelidis, 1993; Schwienhorst, 2008), popularizing online multiuser virtual environments (e.g., Second Life) and massively multiplayer online games (e.g., World of Warcraft). In these autonomous learning environments entailing “independent action” and “decision- making” (Little, 1991, p. 4), it is essential that learners become cognizant of how to learn by raising their metalinguistic awareness and participating in tasks that motivate L2 communication. Fischer (2007) and Schwienhorst (2008) argue that learners in these environments should develop metacognitive abilities, strategies, and have opportunities for reflection (e.g., on input characteristics or their own learning strategies).
#####
#####
@inproceedings{granstrom2004towards,
  title={Towards a virtual language tutor},
  author={Granstr{\"o}m, Bj{\"o}rn},
  booktitle={InSTIL/ICALL Symposium 2004},
  year={2004}
}
In learning a foreign language, visual signals may in many contexts be more important than verbal signals. During the process of acquiring a language, both child L1 speakers and adult L2 speakers rely on gestures to supplement their own speech production (McNeill, 1992; Gullberg, 1998). Adult L2 speakers often make more exten- sive use of gestures than L1 speakers, especially when searching for words or phrases in the new language. In this context, gestures have a compen- satory function in production, often substituting for an unknown word or phrase. L2 listeners may also make greater use of visual cues to aid the conversational flow than do L1 listeners. In this respect, parallels can be made between the situa- tion of the hearing impaired listener and the L2 learner (McAllister 1998).
It has been found that the integration of seg- mental audio-visual information is affected by the relationship between the language of the speaker and that of the listener. Subjects listening to a for- eign language often incorporate visual informa- tion to a greater extent than do subjects listening to their own language (Kuhl et al. 1994; Burnham and Lau 1999). Furthermore, in a conversation, the L2 learner must not only concentrate on seg- mental phonological features of the target lan- guage while remembering newly learned lexical items, but must also respond to questions at the same time. This task creates a cognitive load for the L2 listener which is in many respects much different from that for the L1 user of a spoken dialogue system. Thus, the compensatory possi- bilities of modality transforms and enhancements of the visual modality are well worth exploring not only concerning segmental, phoneme-level information but also for prosodic and conversa- tional information.
2 CALL-related projects at CTT
The CALL research at the Centre for Speech Technology (CTT) focuses on building a Virtual Language Tutor, using an animated talking agent, that addresses these issues, serving as a conversa- tional partner, teacher and an untiring model of pronunciation, who can pick exercises from a training library depending on the user’s needs.
#####
#####
@article{heift2001intelligent,
  title={Intelligent language tutoring systems for grammar practice},
  author={Heift, Trude},
  journal={Zeitschrift f{\"u}r Interkulturellen Fremdsprachenunterricht},
  volume={6},
  number={2},
  year={2001}
}
The present paper discusses building a more flexible Web-based grammar practice environment around an Intelligent Language Tutoring System (ILTS). While ILTSs employ Natural Language Processing (NLP) and thus require programming and linguistic expertise, they provide error-specific feedback and flexibility in handling student answers. Sound, graphics and/or videos can also be implemented to achieve a more varied, authentic and contextualized learning environment.
#####
#####
@article{nagata:02,
	Author = {Noriko Nagata},
	Date-Added = {2010-08-12 15:04:17 -0400},
	Date-Modified = {2010-10-19 12:57:46 -0400},
	Journal = {{CALICO} Journal},
	Key = {system},
	Keywords = {ICALL, Japanese},
	Note = {\url{http://www.usfca.edu/japanese/CALICO02.pdf}},
	Number = 3,
	Pages = {583-599},
	Title = {{BANZAI}: An Application of Natural Language Processing to Web based Language Learning},
	Volume = 19,
	Year = 2002}

The BANZAI program, however, is written in Java, which pro- vides excellent support both for sophisticated NLP programming and ap- pealing multimedia applications. As a result, the BANZAI interface is user friendly and visually appealing, making full use of digital photographs, computer graphics, pull down menus, button selections, and Japanese sounds. Each exercise in BANZAI is framed in a conversational setting, along with a relevant photographic or graphical image of Japan, and asks learners to produce a target sentence that is likely to be uttered in real communicative situations.
#####
#####
