2021/02/16

Here's the remaining work:

1. Split "Method" into "Pilot" and "Method"
	A. Ch 3: "Pilot": 2/16: COMPLETE
	B. Ch 6: "Method": 2/17
	C. Revise "Data", "Annotation" accordingly: 2/18
2. Write "Optimization"
	A. Transitivity: 2/22
	B. Targeting: 2/23
	C. Familiarity: 2/24
	D. Primacy: 2/25
	E. Term Norm: COMPLETE
	F. Term representation: 2/19
	G. Combinations and trends: 3/2
	H. Bert vs Me: 3/4
3. Write Lit Review: 3/12
4. Write Intro: 3/22
5. Write Conclusion: 3/31


2021/02/24:
Today I want to grind out all the stats results I need from that csv of 360 spearman scores.



2021/02/26, Friday.
Meeting with Markus in 10 minutes.
TODO:
Fix term norm results table (make parallel to others)
Add BERT (baseline) scores throughout
Add discussion to results
	dig into what the scores represent, guided by stats, deviations from BERT
	Example:
		Term Representation:
			ldh has highest mean, but xdx has highest max (and highest min)
			xdh has highest median
			What's the story here?
			
From meeting:
Investigate p values for mins and maxs and go from there
Investigate Table 6.6--these probably shouldn't be negatives!

Check in in a week with email updates;
Meet on 3/12 at 1:30pm.
################################################################################


2021/02/28, Sunday. BERT.
################################################################################

2021/03/01. Monday. BERT.
Today:
Complete BERT script;
Run BERT on my data;
Generate Spearman scores (BERT vs Weighted Annotation);
DONE;
Tomorrow: modify and rerun thesis_spearman_stats.py to include BERT scores
################################################################################

2021/03/09. Tuesday.
When BERT is finished running on all N14 samples, run get_bert_spearman_correlations.py.
update thesis_bert_spearman_stats.py (cf thesis_spearman_stats.py); run it.
DONE

##
ARGH! I've been using BERT in training mode (default?); this results in non-deterministic scores.
I'm going to run it again in "eval" mode.:
#
Run BERT N14 vs N70:
change bert_vs_sails.py: train_sample = 'N14'
change get_bert_spearman_correlations.py: train_sample = 'N14'
change thesis_bert_spearman_stats.py: train_sample = 'N14'
python bert_vs_sails.py
python get_bert_spearman_correlations.py
python thesis_bert_spearman_stats.py
DONE ALL
#
Run BERT N50 vs N70:
change bert_vs_sails.py: train_sample = 'N50'
change get_bert_spearman_correlations.py: train_sample = 'N50'
change thesis_bert_spearman_stats.py: train_sample = 'N50'
python bert_vs_sails.py
DONE
python get_bert_spearman_correlations.py
DONE
python thesis_bert_spearman_stats.py
DONE
#
###
TODO:
UPDATE ALL CHAPTER 6 TABLES WRT BERT SCORES!
###


################################################################################
2021-03-12.
Updating Chapter 6 now.
TODO:
Regenerate / check numbers for term norm table (currently 6.6); reconcile this table format with others throughout chapter 6.
Write discussion of Spearman correlation; why use Spearman (vs Pearson, etc)? What is the range of Spearman scores and what do they mean? (1.0, 0, -0.5, -1.0)
Write discussion of BERT; what it is/does, how it works; training data; model and implementation used;


Questions for Markus:
How to best highlight information in the Tables?
Does it make sense to highlight the highest (or lowest) standard deviation?

################################################################################
2021-03-26.
TODO:
Complete Familiarity experiments and tables;
################################################################################
Discussion of BERT / SBERT;
inputs, outputs;
mention and cite architecture, but not in detail;
what do we learn from using BERT w.r.t. my system? BERT wins, so we should abandon my system? (NO, but elaborate)
################################################################################
Email Markus on 4/2;
meet again on 4/9;

################################################################################
################################################################################
TODO:
###
CHANGE TO N14 and run:
python get_all_tfidf_cosines-weighted_deps.py (DONE)

CHANGE TO N14 and run:
python get_all_spearman_correlations.py DONE

CHANGE TO N14 and run:
python thesis_spearman_stats.py DONE

###
CHANGE TO F14 and run:
python get_all_tfidf_cosines-weighted_deps.py DONE, paused here;

CHANGE TO F14 and run:
python get_all_spearman_correlations.py DONE

CHANGE TO F14 and run:
python thesis_spearman_stats.py DONE

###
CHANGE TO N50 and run:
python get_all_tfidf_cosines-weighted_deps.py DONE

CHANGE TO N50 and run:
python get_all_spearman_correlations.py DONE

CHANGE TO N50 and run:
python thesis_spearman_stats.py DONE

## For UNWEIGHTED F14 and N14 "term_vectors" folders -- restore these from Github
################################################################################
################################################################################
Citations, Lit Review, etc.
#####
@article{yamazaki2014,
  title={Toward integrative CALL: A progressive outlook on the history, trends, and issues of CALL},
  author={Yamazaki, Kasumi},
  journal={TAPESTRY},
  volume={6},
  number={1},
  pages={6},
  year={2014}
}
"...sociocultural theories of learning, mainly named as Kolb’s (1984) experiential learning and Lave and Wenger’s (1991) situated learning, which emphasize that learning occurs in a communicative context through concrete and direct experiences. Learning in this approach is generally exploratory, thus learners’ autonomy, engagement, and, most importantly, motivation are often found to be the most critical elements of contemporary CALL research (cf. Rahimi & Yodollahi, 2011; Ushioda, 2000; Schwienhorst, 2002; Mohammadi, Ghorbani, & Hamidi, 2011; AbuSeileek, 2012)."
#####
#####
@article{collentine2011,
  title={Learner autonomy in a task-based 3D world and production},
  author={Collentine, Karina},
  journal={Language Learning \& Technology},
  volume={15},
  number={3},
  pages={50--67},
  year={2011},
  publisher={University of Hawaii National Foreign Language Resource Center}
}
With widespread access to technology, learners are increasingly using CALL materials in a learner- centered approach where they take control of their own learning, on their own time, and for their own purposes. These materials include virtual and 3D environments with gaming-like experiences (Darasawang & Reinders, 2010; Sykes, 2009). Highly interactive, multi-sensory environments provide access to real world simulations (Pantelidis, 1993; Schwienhorst, 2008), popularizing online multiuser virtual environments (e.g., Second Life) and massively multiplayer online games (e.g., World of Warcraft). In these autonomous learning environments entailing “independent action” and “decision- making” (Little, 1991, p. 4), it is essential that learners become cognizant of how to learn by raising their metalinguistic awareness and participating in tasks that motivate L2 communication. Fischer (2007) and Schwienhorst (2008) argue that learners in these environments should develop metacognitive abilities, strategies, and have opportunities for reflection (e.g., on input characteristics or their own learning strategies).
#####
#####
@inproceedings{granstrom2004towards,
  title={Towards a virtual language tutor},
  author={Granstr{\"o}m, Bj{\"o}rn},
  booktitle={InSTIL/ICALL Symposium 2004},
  year={2004}
}
In learning a foreign language, visual signals may in many contexts be more important than verbal signals. During the process of acquiring a language, both child L1 speakers and adult L2 speakers rely on gestures to supplement their own speech production (McNeill, 1992; Gullberg, 1998). Adult L2 speakers often make more exten- sive use of gestures than L1 speakers, especially when searching for words or phrases in the new language. In this context, gestures have a compen- satory function in production, often substituting for an unknown word or phrase. L2 listeners may also make greater use of visual cues to aid the conversational flow than do L1 listeners. In this respect, parallels can be made between the situa- tion of the hearing impaired listener and the L2 learner (McAllister 1998).
It has been found that the integration of seg- mental audio-visual information is affected by the relationship between the language of the speaker and that of the listener. Subjects listening to a for- eign language often incorporate visual informa- tion to a greater extent than do subjects listening to their own language (Kuhl et al. 1994; Burnham and Lau 1999). Furthermore, in a conversation, the L2 learner must not only concentrate on seg- mental phonological features of the target lan- guage while remembering newly learned lexical items, but must also respond to questions at the same time. This task creates a cognitive load for the L2 listener which is in many respects much different from that for the L1 user of a spoken dialogue system. Thus, the compensatory possi- bilities of modality transforms and enhancements of the visual modality are well worth exploring not only concerning segmental, phoneme-level information but also for prosodic and conversa- tional information.
2 CALL-related projects at CTT
The CALL research at the Centre for Speech Technology (CTT) focuses on building a Virtual Language Tutor, using an animated talking agent, that addresses these issues, serving as a conversa- tional partner, teacher and an untiring model of pronunciation, who can pick exercises from a training library depending on the user’s needs.
#####
#####
@article{heift2001intelligent,
  title={Intelligent language tutoring systems for grammar practice},
  author={Heift, Trude},
  journal={Zeitschrift f{\"u}r Interkulturellen Fremdsprachenunterricht},
  volume={6},
  number={2},
  year={2001}
}
The present paper discusses building a more flexible Web-based grammar practice environment around an Intelligent Language Tutoring System (ILTS). While ILTSs employ Natural Language Processing (NLP) and thus require programming and linguistic expertise, they provide error-specific feedback and flexibility in handling student answers. Sound, graphics and/or videos can also be implemented to achieve a more varied, authentic and contextualized learning environment.
#####
#####
@article{nagata:02,
	Author = {Noriko Nagata},
	Date-Added = {2010-08-12 15:04:17 -0400},
	Date-Modified = {2010-10-19 12:57:46 -0400},
	Journal = {{CALICO} Journal},
	Key = {system},
	Keywords = {ICALL, Japanese},
	Note = {\url{http://www.usfca.edu/japanese/CALICO02.pdf}},
	Number = 3,
	Pages = {583-599},
	Title = {{BANZAI}: An Application of Natural Language Processing to Web based Language Learning},
	Volume = 19,
	Year = 2002}

The BANZAI program, however, is written in Java, which pro- vides excellent support both for sophisticated NLP programming and ap- pealing multimedia applications. As a result, the BANZAI interface is user friendly and visually appealing, making full use of digital photographs, computer graphics, pull down menus, button selections, and Japanese sounds. Each exercise in BANZAI is framed in a conversational setting, along with a relevant photographic or graphical image of Japan, and asks learners to produce a target sentence that is likely to be uttered in real communicative situations.
#####
#####
