\chapter{Related Work}
\label{chap:lit}

%
%@article{alexopoulou2017task,
%  title={Task effects on linguistic complexity and accuracy: A large-scale learner corpus analysis employing natural language processing techniques},
%  author={Alexopoulou, Theodora and Michel, Marije and Murakami, Akira and Meurers, Detmar},
%  journal={Language Learning},
%  volume={67},
%  number={S1},
%  pages={180--208},
%  year={2017},
%  publisher={Wiley Online Library}
%}
%
%Justifying reliance on NLP tools to process NNS data:
%However, prior studies have shown that native language taggers and parsers perform fairly well on the learner data in EFCAMDAT (Geertzen et al., 2014). For example, Alexopoulou, Geertzen, Korhonen, and Meurers (2015) evaluated the accuracy of extraction of relative clauses, reporting an F score of 83.9%, and found that state-of-the-art NLP tools provide reasonable quality.
%
%#####
%
%
%
%
%@article{papadimitriou2021multilingual,
%  title={Multilingual BERT, Ergativity, and Grammatical Subjecthood},
%  author={Papadimitriou, Isabel and Chi, Ethan A and Futrell, Richard and Mahowald, Kyle},
%  journal={Proceedings of the Society for Computation in Linguistics},
%  volume={4},
%  number={1},
%  pages={425--426},
%  year={2021}
%}
%###
%
%@article{yamazaki2014,
%  title={Toward integrative CALL: A progressive outlook on the history, trends, and issues of CALL},
%  author={Yamazaki, Kasumi},
%  journal={TAPESTRY},
%  volume={6},
%  number={1},
%  pages={6},
%  year={2014}
%}
%"...sociocultural theories of learning, mainly named as Kolb’s (1984) experiential learning and Lave and Wenger’s (1991) situated learning, which emphasize that learning occurs in a communicative context through concrete and direct experiences. Learning in this approach is generally exploratory, thus learners’ autonomy, engagement, and, most importantly, motivation are often found to be the most critical elements of contemporary CALL research (cf. Rahimi & Yodollahi, 2011; Ushioda, 2000; Schwienhorst, 2002; Mohammadi, Ghorbani, & Hamidi, 2011; AbuSeileek, 2012)."
%#####
%#####
%@article{collentine2011,
%  title={Learner autonomy in a task-based 3D world and production},
%  author={Collentine, Karina},
%  journal={Language Learning \& Technology},
%  volume={15},
%  number={3},
%  pages={50--67},
%  year={2011},
%  publisher={University of Hawaii National Foreign Language Resource Center}
%}
%With widespread access to technology, learners are increasingly using CALL materials in a learner- centered approach where they take control of their own learning, on their own time, and for their own purposes. These materials include virtual and 3D environments with gaming-like experiences (Darasawang & Reinders, 2010; Sykes, 2009). Highly interactive, multi-sensory environments provide access to real world simulations (Pantelidis, 1993; Schwienhorst, 2008), popularizing online multiuser virtual environments (e.g., Second Life) and massively multiplayer online games (e.g., World of Warcraft). In these autonomous learning environments entailing “independent action” and “decision- making” (Little, 1991, p. 4), it is essential that learners become cognizant of how to learn by raising their metalinguistic awareness and participating in tasks that motivate L2 communication. Fischer (2007) and Schwienhorst (2008) argue that learners in these environments should develop metacognitive abilities, strategies, and have opportunities for reflection (e.g., on input characteristics or their own learning strategies).
%#####
%#####
%@inproceedings{granstrom2004towards,
%  title={Towards a virtual language tutor},
%  author={Granstr{\"o}m, Bj{\"o}rn},
%  booktitle={InSTIL/ICALL Symposium 2004},
%  year={2004}
%}
%In learning a foreign language, visual signals may in many contexts be more important than verbal signals. During the process of acquiring a language, both child L1 speakers and adult L2 speakers rely on gestures to supplement their own speech production (McNeill, 1992; Gullberg, 1998). Adult L2 speakers often make more exten- sive use of gestures than L1 speakers, especially when searching for words or phrases in the new language. In this context, gestures have a compen- satory function in production, often substituting for an unknown word or phrase. L2 listeners may also make greater use of visual cues to aid the conversational flow than do L1 listeners. In this respect, parallels can be made between the situa- tion of the hearing impaired listener and the L2 learner (McAllister 1998).
%It has been found that the integration of seg- mental audio-visual information is affected by the relationship between the language of the speaker and that of the listener. Subjects listening to a for- eign language often incorporate visual informa- tion to a greater extent than do subjects listening to their own language (Kuhl et al. 1994; Burnham and Lau 1999). Furthermore, in a conversation, the L2 learner must not only concentrate on seg- mental phonological features of the target lan- guage while remembering newly learned lexical items, but must also respond to questions at the same time. This task creates a cognitive load for the L2 listener which is in many respects much different from that for the L1 user of a spoken dialogue system. Thus, the compensatory possi- bilities of modality transforms and enhancements of the visual modality are well worth exploring not only concerning segmental, phoneme-level information but also for prosodic and conversa- tional information.
%2 CALL-related projects at CTT
%The CALL research at the Centre for Speech Technology (CTT) focuses on building a Virtual Language Tutor, using an animated talking agent, that addresses these issues, serving as a conversa- tional partner, teacher and an untiring model of pronunciation, who can pick exercises from a training library depending on the user’s needs.
%#####
%#####
%@article{heift2001intelligent,
%  title={Intelligent language tutoring systems for grammar practice},
%  author={Heift, Trude},
%  journal={Zeitschrift f{\"u}r Interkulturellen Fremdsprachenunterricht},
%  volume={6},
%  number={2},
%  year={2001}
%}
%The present paper discusses building a more flexible Web-based grammar practice environment around an Intelligent Language Tutoring System (ILTS). While ILTSs employ Natural Language Processing (NLP) and thus require programming and linguistic expertise, they provide error-specific feedback and flexibility in handling student answers. Sound, graphics and/or videos can also be implemented to achieve a more varied, authentic and contextualized learning environment.
%#####
%#####
%@article{nagata:02,
%	Author = {Noriko Nagata},
%	Date-Added = {2010-08-12 15:04:17 -0400},
%	Date-Modified = {2010-10-19 12:57:46 -0400},
%	Journal = {{CALICO} Journal},
%	Key = {system},
%	Keywords = {ICALL, Japanese},
%	Note = {\url{http://www.usfca.edu/japanese/CALICO02.pdf}},
%	Number = 3,
%	Pages = {583-599},
%	Title = {{BANZAI}: An Application of Natural Language Processing to Web based Language Learning},
%	Volume = 19,
%	Year = 2002}
%
%The BANZAI program, however, is written in Java, which pro- vides excellent support both for sophisticated NLP programming and ap- pealing multimedia applications. As a result, the BANZAI interface is user friendly and visually appealing, making full use of digital photographs, computer graphics, pull down menus, button selections, and Japanese sounds. Each exercise in BANZAI is framed in a conversational setting, along with a relevant photographic or graphical image of Japan, and asks learners to produce a target sentence that is likely to be uttered in real communicative situations.


This dissertation lies at the intersection of language testing, second language acquisition (SLA), intelligent computer-assisted language learning (ICALL), corpus linguistics and natural language processing (NLP). My work here is much indebted to related research in these areas, and this chapter will summarize some of the most relevant studies.

\lk{Maybe it's better to have a P here summarizing my ``ethos'' (low resource, content focused, interpretable) instead of spreading that out below.}

I begin in Section~\ref{section:ICALLinterp} with a discussion of the importance of transparency and interpretability in ICALL and language testing. In  Section~\ref{section:ICALLoverview}, I examine approaches to ICALL that relate to and inform this dissertation. In Section~\ref{section:learnerCorpora}, I summarize research involving the collection, annotation or content analysis of task-based learner corpora. A brief overview of the NLP tools and methods used in my work is given in Section~\ref{section:NLP}. Finally, in Section~\ref{section:myPreviousWork}, I present a summary of my own previous work related to this dissertation. 

\section{On interpretability for learner applications}
\label{section:ICALLinterp}

(See also Section~\ref{section:imageProcessing}; this should address the use of sentence encoders like BERT and their use in conjunction with image recognition technology).

This work would be remiss without discussing the role of machine learning (ML) in current NLP, given that such technologies are largely absent from this dissertation. Recent years have seen the rapid development of ML technologies like neural networks and deep learning. \lk{What is ML good at? citations!} These technologies have been widely implemented in areas like NLP and computer vision, often with impressive gains in performance. They can also lead to reductions in the amount of human expertise needed to automate tasks like syntactic labeling, voice recognition and synthesis, and object and facial recognition. \lk{cite stuff} Naturally, this also means significant reductions in the cost of such systems. A major drawback with many such ML technologies, however is the loss of interpretability. For example, \textit{word embeddings} (such as Word2Vec) \lk{cite} are ML based NLP tools suitable for many tasks involving the processing of linguistic meaning or structures. Word2Vec essentially ``learns'' an approximation of the meanings and grammatical usage of words by observing them in context. Instead of relying on expert annotation of features like part-of-speech, sentence structure and morphology to train a model, the system needs only large amounts of raw text. From this text, it observes large numbers of features, such as the average distance between instances of \textit{Word A} and \textit{Word B}. It reduces these raw features to a (still quite large) number of abstract features, or ``latent variables'', which form a vector of numeric values; this vector then serves as a representation of a word's ``meaning''. In a classic example, if one takes the vector for ``queen'', subtracts the vector for ``female'' and adds the vector for ``male'', the resulting vector is roughly equivalent to that of ``king''.

\lk{this is all very cf Brian Riordan's alumni talk... similar sources would be ideal}
For many applications, the capabilities and cost reduction of ML make it an attractive and suitable choice; this is certainly the case with many NLP tasks. The use of ML tools with learner language is problematic on at least two fronts, however. First, such tools are typically designed for and trained on well-formed, native-like text (or speech). As mentioned, these tools generally do not rely on annotation in their training data; instead, they make up for this lack of expertise by the sheer volume of training data they consume. Including real learner data on the scale required by ML tools would be impractical if not impossible for most researchers. As a result of ML tools' training on mostly native-like data, they are ill-equipped for processing the variability and ambiguity of learner language. For example, native English trained NLP tools expect regular sentence punctuation; text from a beginning English learner lacking in punctuation could therefore be misconstrued as having longer sentences and thus higher proficiency \cite{MeurersDickinson2017}. Second, and perhaps more importantly, tools that rely heavily on ML are inherently less interpretable than ``classical'' NLP tools. Because classical NLP tools are trained on expert annotation, their output is generally determined by the kinds of features that are annotated in the training corpus. This means linguistic researchers can design NLP tools and pipelines that produce output precisely suited for their research questions, so long as they have the resources to produce adequate training corpora. This is not the case with ML based tools, however. Due to their reliance on abstract features and latent variables, these newer tools are largely ``black box'' technologies; raw data goes in and processed data comes out, but even the architect of such a system cannot explain exactly how or why the analysis was produced. In a language learning application, this is problematic because it means the development of a pedagogically sound feedback system for the learner is not possible; the features underlying the analysis are not accessible or interpretable. The outcomes of language testing can have a tremendous impact on a test taker's future, and in such a high stakes application, the lack of interpretability can be even more problematic. Arguably, it is far better for all stakeholders if a language test can deliver not only a score, but also a rationale for that score, such as which kinds of errors a test taker makes and in what contexts. This need for interpretable features was one of a few major factors in the decision to choose classical NLP over newer ML tools in this dissertation, and most of the related studies discussed here take similar approaches.


\section{Image processing}
\label{section:imageProcessing}
This should probably include discussion of ML approaches at image ``encoding/decoding'' and their use in tandem with sentence encoders (BERT, etc.). Ask Ben S. for reading suggestions?

We want to touch on image processing / automatic captioning / use of semantic primatives, etc. -- linguistic annotation of images. NOT a deep discussion, but we need to acknowledge that there are other fields working on the relations between images and text, and give an idea of what some approaches are and how they work, and how they might relate to my work and the work discussed in my lit review.

\section{An overview of ICALL and content analysis}
\label{section:ICALLoverview}
This dissertation began as an experiment in bootstrapping NLP tools and learner data to achieve more meaning-based (and meaningful) ICALL. I do not attempt a full-fledged ICALL system, but I explore mechanisms for performing the core content analysis that could be implemented in a setting like a game, an interactive language tutor (ILT) or a language test. I see this work as a push toward relatively low-cost, extendable ICALL with an emphasis on content over form. Each of these points is an attempt at a more interdisciplinary and pedagogically sound approach to ICALL. In keeping with this ethos, this section focuses on ICALL research that primarily uses existing NLP tools and allows for free user input (as opposed to menu-based input).

One relatively well-documented ICALL system is TAGARELA, an application for adult learners of Portuguese \cite{amaral2007designing,amaral:meurers:user:07}. In more recent updates to the system, the authors describe TAGARELA's ``Unstructured Information Management Architecture (UIMA),'' which is effectively a collection of text relevant to the tasks that are enriched with multiple annotations relating to both form and meaning. TAGARELA relies on a set of NLP modules implemented in a flexible, task-based, free input ICALL system \cite{Amaral.Meurers.Ziai-11}. The system includes six different activity types: reading, listening, description, rephrasing, vocabulary and fill-in-the-blank. These different tasks require different types of (textual) learner input as well as different subsets of the NLP modules for input processing and the generation of feedback.

Before developing anything, the TAGARELA team began their work with the creation of a ``taxonomy of expected errors,'' gleaned from their analysis of a corpus of written assignments from learners of Portuguese. The authors describe their approach as ``data-driven rather than process-driven''. In many ways, this bucks a tendency among many ICALL developers to simply address the kinds of errors NLP tools can readily identify. \lk{cite DuoLingo? etc.}What is needed instead is ICALL development informed by second language acquisition research and by the kinds of challenges learners face, as borne out by real data. \lk{cite Ellis, Meurers}These errors annotated in the learner data and handled by TAGARELA cover both form and meaning, with error types consisting of, for example, \textit{spelling}, \textit{agreement} and \textit{word choice}.

One major advantage of TAGARELA's approach to ICALL is its ability to accommodate multiple activities with only a handful of existing and custom NLP modules along with a small number of carefully chosen and annotated model responses. The current dissertation found inspiration in TAGARELA's prioritization of the handling of errors related to meaning and its reliance on ordinary and interpretable NLP tools -- primarily a tokenizer, part of speech tagger and syntactic parser. 

\section{Learner corpora}
\label{section:learnerCorpora}
Here I will discuss task-based learner corpora research that relates to my work. This includes discussions of task design, data collection, annotation schemes, and automatic processing. I focus in particular on the learner content analysis research conducted by two clusters of researchers: one primarily associated with The Ohio State University and consisting of Detmar Meurers and colleagues, and the other primarily associated with Educational Testing Services (ETS) and consisting of Martin Chodorow, Swapna Somasundaran and Joel Tetrault and colleagues. 

Here are some papers I discussed briefly in my BEA 2018 paper:

\cite{leacock:ea:14}

\cite{kyle2015automatically}

\cite{weigle2013english}

\cite{amaral:meurers:user:07}

\cite{Meurers.Dickinson-17}

\cite{heift:schulze:07}

\cite{somasundaran:ea:15}

\cite{bailey:meurers:08}

\cite{meurers2011evaluating}

\cite{somasundaran:chodorow:14}

\cite{cahill-et-al:14}

\cite{ragheb:dickinson:14a}

\cite{foster2009native}

\cite{cho2013investigating}

\cite{landis1977measurement}

\cite{artstein:massimo:2008}

\cite{tetreault-chodorow:2008:HJCL}

\cite{tetreault:chodorow:08}

\section{Language assessment}
\label{section:languageAssessment}

\section{NLP tools and methods}
\label{section:NLP}
%
%\section{My previous work}
%\label{section:myPreviousWork}
%Here I will discuss the work I have previously done in this area, including the papers given in the subsections below.
%
%\subsection{2013}
%\cite{king:dickinson:13}
%
%\begin{figure}
%\includegraphics[width=.7\textwidth]{figures/exampleprompt2.jpg}
%\caption{This is an example figure from \citet{king:dickinson:13}.}
%\label{figure:KandD2013}
%\end{figure}
%
%\subsection{2014}
%\citet{king:dickinson:14}
%
%\subsection{2016}
%\citep{king:dickinson:16}
%
%\subsubsection{Bag-of-dependencies}
%Here we could discuss the switch to a bag-of-dependencies approach, the use of tf-idf and the use of vector cosine distance for ranking responses.
%
%\subsubsection{Clustering}
%Here we could briefly mention the clustering experiments we did in the 2016 paper. But really, I'd rather not, because I don't intend to repeat them in the dissertation.
%
%\subsection{2018}
%\cite{king:dickinson:18}
%
%\begin{figure}
%\includegraphics[width=.7\textwidth]{figures/I29.jpg}
%\caption{This is an example figure from \citet{king:dickinson:18}.}
%\label{figure:KandD2018}
%\end{figure}


% This is a figure in landscape orientation
%\begin{sidewaysfigure}
%\includegraphics[width=\textwidth]{figures/exampleFigure.png}
%\caption{This is another example Figure, rotated to landscape orientation.}
%\label{LandscapeFigure}
%\end{sidewaysfigure}
