%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Do not edit these lines unless you wish to customize
% the template
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newgeometry{left=1in}

\begin{center}

\yourName\\
\thesisTitle

\end{center}

\vspace{1.5\baselineskip}

An intelligent computer-assisted language learning (ICALL) system is an application to provide users instruction and practice as they learn a second language.
In order to be more effective and more widely adopted, ICALL must better align with second language acquisition (SLA) research, moving away from menu-based or fill-in-the-blank exercises and toward the task-based and communicative methods the research supports.

As a first step in this direction, this dissertation presents a mechanism by which an ICALL system can judge the appropriateness of an advanced English learner's response to an image-based prompt simply by comparison with a collection of crowdsourced native speaker (NS) responses. It relies on well-established natural language processing (NLP) techniques, namely syntactic dependency parsing, lemmatization and term frequency-inverse document frequency (tf-idf). To ensure broader success, this method was designed to be flexible, expandable and low-cost by relying on readily available tools and using crowdsourced models instead of custom rules or expert knowledge. Compared to more advanced machine learning NLP approaches, my system maintains a high degree of transparency, making it ideal for integration with an ICALL feedback module.

To evaluate my approach, I collected a corpus of over 13,000 picture description task (PDT) responses from NSs and English learners. I developed and applied an annotation scheme of five binary features intended to capture aspects of nativelikeness and semantic appropriateness, and showed these features to have a high degree of inter-annotator agreement. I used a preference task to establish feature weights and benchmark rankings of learner responses. I showed that my system output generally correlates well with the benchmark rankings and shows a promising degree of accuracy in predicting the annotations. 

\ifdefined\committeeMemberFourTypedName

\null\hfill \myRule\\
\null\hfill \committeeChairpersonTypedName, \committeeChairpersonPostNominalInitials\\
\null\hfill \myRule\\
\null\hfill \committeeMemberTwoTypedName, \committeeMemberTwoPostNominalInitials\\
\null\hfill \myRule\\
\null\hfill \committeeMemberThreeTypedName, \committeeMemberThreePostNominalInitials\\
\null\hfill \myRule\\
\null\hfill \committeeMemberFourTypedName, \committeeMemberFourPostNominalInitials\\

\ifdefined\committeeMemberFiveTypedName
\null\hfill \myRule\\
\null\hfill \committeeMemberFiveTypedName, \committeeMemberFivePostNominalInitials\\
\fi

\fi
\restoregeometry
